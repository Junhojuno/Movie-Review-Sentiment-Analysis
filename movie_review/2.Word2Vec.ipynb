{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The sentiment labels are:\n",
    "\n",
    "    0 - negative\n",
    "    1 - somewhat negative\n",
    "    2 - neutral\n",
    "    3 - somewhat positive\n",
    "    4 - positive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PhraseId</th>\n",
       "      <th>SentenceId</th>\n",
       "      <th>Phrase</th>\n",
       "      <th>Sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>156055</th>\n",
       "      <td>156056</td>\n",
       "      <td>8544</td>\n",
       "      <td>Hearst 's</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156056</th>\n",
       "      <td>156057</td>\n",
       "      <td>8544</td>\n",
       "      <td>forced avuncular chortles</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156057</th>\n",
       "      <td>156058</td>\n",
       "      <td>8544</td>\n",
       "      <td>avuncular chortles</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156058</th>\n",
       "      <td>156059</td>\n",
       "      <td>8544</td>\n",
       "      <td>avuncular</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156059</th>\n",
       "      <td>156060</td>\n",
       "      <td>8544</td>\n",
       "      <td>chortles</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        PhraseId  SentenceId                     Phrase  Sentiment\n",
       "156055    156056        8544                  Hearst 's          2\n",
       "156056    156057        8544  forced avuncular chortles          1\n",
       "156057    156058        8544         avuncular chortles          3\n",
       "156058    156059        8544                  avuncular          2\n",
       "156059    156060        8544                   chortles          2"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = pd.read_csv(\"../train.tsv\", delimiter='\\t', quoting=3)\n",
    "train.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PhraseId</th>\n",
       "      <th>SentenceId</th>\n",
       "      <th>Phrase</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>66287</th>\n",
       "      <td>222348</td>\n",
       "      <td>11855</td>\n",
       "      <td>A long-winded , predictable scenario .</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66288</th>\n",
       "      <td>222349</td>\n",
       "      <td>11855</td>\n",
       "      <td>A long-winded , predictable scenario</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66289</th>\n",
       "      <td>222350</td>\n",
       "      <td>11855</td>\n",
       "      <td>A long-winded ,</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66290</th>\n",
       "      <td>222351</td>\n",
       "      <td>11855</td>\n",
       "      <td>A long-winded</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66291</th>\n",
       "      <td>222352</td>\n",
       "      <td>11855</td>\n",
       "      <td>predictable scenario</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       PhraseId  SentenceId                                  Phrase\n",
       "66287    222348       11855  A long-winded , predictable scenario .\n",
       "66288    222349       11855    A long-winded , predictable scenario\n",
       "66289    222350       11855                         A long-winded ,\n",
       "66290    222351       11855                           A long-winded\n",
       "66291    222352       11855                    predictable scenario"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = pd.read_csv(\"../test.tsv\", delimiter='\\t', quoting=3)\n",
    "test.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PhraseId</th>\n",
       "      <th>SentenceId</th>\n",
       "      <th>Phrase</th>\n",
       "      <th>Sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>A series of escapades demonstrating the adage ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>A series of escapades demonstrating the adage ...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>A series</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>A</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>series</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PhraseId  SentenceId                                             Phrase  \\\n",
       "0         1           1  A series of escapades demonstrating the adage ...   \n",
       "1         2           1  A series of escapades demonstrating the adage ...   \n",
       "2         3           1                                           A series   \n",
       "3         4           1                                                  A   \n",
       "4         5           1                                             series   \n",
       "\n",
       "   Sentiment  \n",
       "0          1  \n",
       "1          2  \n",
       "2          2  \n",
       "3          2  \n",
       "4          2  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 156060 entries, 0 to 156059\n",
      "Data columns (total 4 columns):\n",
      "PhraseId      156060 non-null int64\n",
      "SentenceId    156060 non-null int64\n",
      "Phrase        156060 non-null object\n",
      "Sentiment     156060 non-null int64\n",
      "dtypes: int64(3), object(1)\n",
      "memory usage: 4.8+ MB\n"
     ]
    }
   ],
   "source": [
    "train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PhraseId ( 156060 ) \n",
      " [     1      2      3 ... 156058 156059 156060]\n",
      "SentenceId ( 8529 ) \n",
      " [   1    2    3 ... 8542 8543 8544]\n",
      "Phrase ( 156060 ) \n",
      " ['A series of escapades demonstrating the adage that what is good for the goose is also good for the gander , some of which occasionally amuses but none of which amounts to much of a story .'\n",
      " 'A series of escapades demonstrating the adage that what is good for the goose'\n",
      " 'A series' ... 'avuncular chortles' 'avuncular' 'chortles']\n",
      "Sentiment ( 5 ) \n",
      " [1 2 3 4 0]\n"
     ]
    }
   ],
   "source": [
    "for i in train.columns:\n",
    "    print(i,'(',train[i].nunique(),')','\\n',train[i].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:1: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PhraseId</th>\n",
       "      <th>SentenceId</th>\n",
       "      <th>Phrase</th>\n",
       "      <th>Sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>A series of escapades demonstrating the adage ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>34</td>\n",
       "      <td>1</td>\n",
       "      <td>the gander , some of which occasionally amuses...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>48</td>\n",
       "      <td>1</td>\n",
       "      <td>but none of which amounts to much of a story</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>50</td>\n",
       "      <td>1</td>\n",
       "      <td>none of which amounts to much of a story</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    PhraseId  SentenceId                                             Phrase  \\\n",
       "0          1           1  A series of escapades demonstrating the adage ...   \n",
       "33        34           1  the gander , some of which occasionally amuses...   \n",
       "47        48           1       but none of which amounts to much of a story   \n",
       "49        50           1           none of which amounts to much of a story   \n",
       "\n",
       "    Sentiment  \n",
       "0           1  \n",
       "33          1  \n",
       "47          1  \n",
       "49          1  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train[train.SentenceId == 1][train.Sentiment == 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PhraseId</th>\n",
       "      <th>SentenceId</th>\n",
       "      <th>Phrase</th>\n",
       "      <th>Sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>63</td>\n",
       "      <td>1</td>\n",
       "      <td>.</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    PhraseId  SentenceId Phrase  Sentiment\n",
       "62        63           1      .          2"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train[train.Phrase == '.']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Issues\n",
    "- 각 SentenceId의 첫 Phrase가 full sentences이고 나머진 일부분들....\n",
    "- 한 글자만으로 이루어진 Phrase가 있어서 stopword를 쓰면 안된다고 판단.\n",
    "- .조차도 버리면 안되는건가..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "from KaggleWord2VecUtility import KaggleWord2VecUtility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\bs4\\__init__.py:219: UserWarning: \"b'.'\" looks like a filename, not markup. You should probably open this file and pass the filehandle into Beautiful Soup.\n",
      "  ' Beautiful Soup.' % markup)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\bs4\\__init__.py:219: UserWarning: \"b'...'\" looks like a filename, not markup. You should probably open this file and pass the filehandle into Beautiful Soup.\n",
      "  ' Beautiful Soup.' % markup)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\bs4\\__init__.py:219: UserWarning: \"b'.'\" looks like a filename, not markup. You should probably open this file and pass the filehandle into Beautiful Soup.\n",
      "  ' Beautiful Soup.' % markup)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\bs4\\__init__.py:219: UserWarning: \"b'...'\" looks like a filename, not markup. You should probably open this file and pass the filehandle into Beautiful Soup.\n",
      "  ' Beautiful Soup.' % markup)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\bs4\\__init__.py:219: UserWarning: \"b'...'\" looks like a filename, not markup. You should probably open this file and pass the filehandle into Beautiful Soup.\n",
      "  ' Beautiful Soup.' % markup)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\bs4\\__init__.py:219: UserWarning: \"b'.'\" looks like a filename, not markup. You should probably open this file and pass the filehandle into Beautiful Soup.\n",
      "  ' Beautiful Soup.' % markup)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\bs4\\__init__.py:219: UserWarning: \"b'.'\" looks like a filename, not markup. You should probably open this file and pass the filehandle into Beautiful Soup.\n",
      "  ' Beautiful Soup.' % markup)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\bs4\\__init__.py:219: UserWarning: \"b'...'\" looks like a filename, not markup. You should probably open this file and pass the filehandle into Beautiful Soup.\n",
      "  ' Beautiful Soup.' % markup)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\bs4\\__init__.py:219: UserWarning: \"b'.'\" looks like a filename, not markup. You should probably open this file and pass the filehandle into Beautiful Soup.\n",
      "  ' Beautiful Soup.' % markup)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\bs4\\__init__.py:219: UserWarning: \"b'.'\" looks like a filename, not markup. You should probably open this file and pass the filehandle into Beautiful Soup.\n",
      "  ' Beautiful Soup.' % markup)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\bs4\\__init__.py:219: UserWarning: \"b'.'\" looks like a filename, not markup. You should probably open this file and pass the filehandle into Beautiful Soup.\n",
      "  ' Beautiful Soup.' % markup)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\bs4\\__init__.py:219: UserWarning: \"b'.'\" looks like a filename, not markup. You should probably open this file and pass the filehandle into Beautiful Soup.\n",
      "  ' Beautiful Soup.' % markup)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\bs4\\__init__.py:219: UserWarning: \"b'.'\" looks like a filename, not markup. You should probably open this file and pass the filehandle into Beautiful Soup.\n",
      "  ' Beautiful Soup.' % markup)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\bs4\\__init__.py:219: UserWarning: \"b'.'\" looks like a filename, not markup. You should probably open this file and pass the filehandle into Beautiful Soup.\n",
      "  ' Beautiful Soup.' % markup)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\bs4\\__init__.py:219: UserWarning: \"b'.'\" looks like a filename, not markup. You should probably open this file and pass the filehandle into Beautiful Soup.\n",
      "  ' Beautiful Soup.' % markup)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\bs4\\__init__.py:219: UserWarning: \"b'.'\" looks like a filename, not markup. You should probably open this file and pass the filehandle into Beautiful Soup.\n",
      "  ' Beautiful Soup.' % markup)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\bs4\\__init__.py:219: UserWarning: \"b'.'\" looks like a filename, not markup. You should probably open this file and pass the filehandle into Beautiful Soup.\n",
      "  ' Beautiful Soup.' % markup)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\bs4\\__init__.py:219: UserWarning: \"b'.'\" looks like a filename, not markup. You should probably open this file and pass the filehandle into Beautiful Soup.\n",
      "  ' Beautiful Soup.' % markup)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\bs4\\__init__.py:219: UserWarning: \"b'...'\" looks like a filename, not markup. You should probably open this file and pass the filehandle into Beautiful Soup.\n",
      "  ' Beautiful Soup.' % markup)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\bs4\\__init__.py:219: UserWarning: \"b'license'\" looks like a filename, not markup. You should probably open this file and pass the filehandle into Beautiful Soup.\n",
      "  ' Beautiful Soup.' % markup)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\bs4\\__init__.py:219: UserWarning: \"b'.'\" looks like a filename, not markup. You should probably open this file and pass the filehandle into Beautiful Soup.\n",
      "  ' Beautiful Soup.' % markup)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\bs4\\__init__.py:219: UserWarning: \"b'.'\" looks like a filename, not markup. You should probably open this file and pass the filehandle into Beautiful Soup.\n",
      "  ' Beautiful Soup.' % markup)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\bs4\\__init__.py:219: UserWarning: \"b'.'\" looks like a filename, not markup. You should probably open this file and pass the filehandle into Beautiful Soup.\n",
      "  ' Beautiful Soup.' % markup)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\bs4\\__init__.py:219: UserWarning: \"b'...'\" looks like a filename, not markup. You should probably open this file and pass the filehandle into Beautiful Soup.\n",
      "  ' Beautiful Soup.' % markup)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\bs4\\__init__.py:219: UserWarning: \"b'.'\" looks like a filename, not markup. You should probably open this file and pass the filehandle into Beautiful Soup.\n",
      "  ' Beautiful Soup.' % markup)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\bs4\\__init__.py:219: UserWarning: \"b'.'\" looks like a filename, not markup. You should probably open this file and pass the filehandle into Beautiful Soup.\n",
      "  ' Beautiful Soup.' % markup)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\bs4\\__init__.py:219: UserWarning: \"b'...'\" looks like a filename, not markup. You should probably open this file and pass the filehandle into Beautiful Soup.\n",
      "  ' Beautiful Soup.' % markup)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\bs4\\__init__.py:219: UserWarning: \"b'...'\" looks like a filename, not markup. You should probably open this file and pass the filehandle into Beautiful Soup.\n",
      "  ' Beautiful Soup.' % markup)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\bs4\\__init__.py:219: UserWarning: \"b'.'\" looks like a filename, not markup. You should probably open this file and pass the filehandle into Beautiful Soup.\n",
      "  ' Beautiful Soup.' % markup)\n"
     ]
    }
   ],
   "source": [
    "sentences = []\n",
    "for phrase in train['Phrase']:\n",
    "    sentences += KaggleWord2VecUtility.review_to_sentences(phrase, remove_stopwords=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "156448"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "logging.basicConfig(\n",
    "    format='%(asctime)s : %(levelname)s : $(massage)s',\n",
    "    level=logging.INFO\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import word2vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-08-15 22:58:31,643 : INFO : $(massage)s\n",
      "2018-08-15 22:58:31,644 : INFO : $(massage)s\n",
      "2018-08-15 22:58:31,660 : INFO : $(massage)s\n",
      "2018-08-15 22:58:31,679 : INFO : $(massage)s\n",
      "2018-08-15 22:58:31,698 : INFO : $(massage)s\n",
      "2018-08-15 22:58:31,719 : INFO : $(massage)s\n",
      "2018-08-15 22:58:31,737 : INFO : $(massage)s\n",
      "2018-08-15 22:58:31,757 : INFO : $(massage)s\n",
      "2018-08-15 22:58:31,774 : INFO : $(massage)s\n",
      "2018-08-15 22:58:31,793 : INFO : $(massage)s\n",
      "2018-08-15 22:58:31,813 : INFO : $(massage)s\n",
      "2018-08-15 22:58:31,831 : INFO : $(massage)s\n",
      "2018-08-15 22:58:31,849 : INFO : $(massage)s\n",
      "2018-08-15 22:58:31,866 : INFO : $(massage)s\n",
      "2018-08-15 22:58:31,884 : INFO : $(massage)s\n",
      "2018-08-15 22:58:31,901 : INFO : $(massage)s\n",
      "2018-08-15 22:58:31,920 : INFO : $(massage)s\n",
      "2018-08-15 22:58:31,931 : INFO : $(massage)s\n",
      "2018-08-15 22:58:31,932 : INFO : $(massage)s\n",
      "2018-08-15 22:58:31,950 : INFO : $(massage)s\n",
      "2018-08-15 22:58:31,951 : INFO : $(massage)s\n",
      "2018-08-15 22:58:31,970 : INFO : $(massage)s\n",
      "2018-08-15 22:58:31,972 : INFO : $(massage)s\n",
      "2018-08-15 22:58:31,973 : INFO : $(massage)s\n",
      "2018-08-15 22:58:31,994 : INFO : $(massage)s\n",
      "2018-08-15 22:58:31,996 : INFO : $(massage)s\n",
      "2018-08-15 22:58:32,085 : INFO : $(massage)s\n",
      "2018-08-15 22:58:32,666 : INFO : $(massage)s\n",
      "2018-08-15 22:58:32,667 : INFO : $(massage)s\n",
      "2018-08-15 22:58:32,670 : INFO : $(massage)s\n",
      "2018-08-15 22:58:32,674 : INFO : $(massage)s\n",
      "2018-08-15 22:58:32,676 : INFO : $(massage)s\n",
      "2018-08-15 22:58:33,248 : INFO : $(massage)s\n",
      "2018-08-15 22:58:33,249 : INFO : $(massage)s\n",
      "2018-08-15 22:58:33,251 : INFO : $(massage)s\n",
      "2018-08-15 22:58:33,255 : INFO : $(massage)s\n",
      "2018-08-15 22:58:33,257 : INFO : $(massage)s\n",
      "2018-08-15 22:58:33,819 : INFO : $(massage)s\n",
      "2018-08-15 22:58:33,821 : INFO : $(massage)s\n",
      "2018-08-15 22:58:33,824 : INFO : $(massage)s\n",
      "2018-08-15 22:58:33,829 : INFO : $(massage)s\n",
      "2018-08-15 22:58:33,830 : INFO : $(massage)s\n",
      "2018-08-15 22:58:34,426 : INFO : $(massage)s\n",
      "2018-08-15 22:58:34,429 : INFO : $(massage)s\n",
      "2018-08-15 22:58:34,431 : INFO : $(massage)s\n",
      "2018-08-15 22:58:34,438 : INFO : $(massage)s\n",
      "2018-08-15 22:58:34,439 : INFO : $(massage)s\n",
      "2018-08-15 22:58:35,001 : INFO : $(massage)s\n",
      "2018-08-15 22:58:35,002 : INFO : $(massage)s\n",
      "2018-08-15 22:58:35,008 : INFO : $(massage)s\n",
      "2018-08-15 22:58:35,009 : INFO : $(massage)s\n",
      "2018-08-15 22:58:35,010 : INFO : $(massage)s\n",
      "2018-08-15 22:58:35,011 : INFO : $(massage)s\n"
     ]
    }
   ],
   "source": [
    "num_features = 40\n",
    "min_count = 20\n",
    "num_worker = 4\n",
    "window = 10\n",
    "downsampling = 1e-3\n",
    "sg = 0\n",
    "model = word2vec.Word2Vec(sentences, workers=num_worker, size=num_features,\n",
    "                          min_count = min_count, window=window,\n",
    "                          sample=downsampling, sg=sg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-08-15 22:58:35,020 : INFO : $(massage)s\n"
     ]
    }
   ],
   "source": [
    "model.init_sims(replace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:1: DeprecationWarning: Call to deprecated `doesnt_match` (Method will be removed in 4.0.0, use self.wv.doesnt_match() instead).\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\gensim\\matutils.py:737: FutureWarning: Conversion of the second argument of issubdtype from `int` to `np.signedinteger` is deprecated. In future, it will be treated as `np.int32 == np.dtype(int).type`.\n",
      "  if np.issubdtype(vec.dtype, np.int):\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'kitchen'"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.doesnt_match(\"man woman child kitchen\".split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:1: DeprecationWarning: Call to deprecated `most_similar` (Method will be removed in 4.0.0, use self.wv.most_similar() instead).\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\gensim\\matutils.py:737: FutureWarning: Conversion of the second argument of issubdtype from `int` to `np.signedinteger` is deprecated. In future, it will be treated as `np.int32 == np.dtype(int).type`.\n",
      "  if np.issubdtype(vec.dtype, np.int):\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('monster', 0.7339290380477905),\n",
       " ('crass', 0.6766730546951294),\n",
       " ('worst', 0.6576613783836365),\n",
       " ('season', 0.6498938798904419),\n",
       " ('equival', 0.6281961798667908),\n",
       " ('buff', 0.6273522973060608),\n",
       " ('holiday', 0.6243687868118286),\n",
       " ('b', 0.6079187393188477),\n",
       " ('phoni', 0.6073557138442993),\n",
       " ('crime', 0.599737286567688)]"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.most_similar(\"horror\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "def makeFeatureVec(words, model, num_features):\n",
    "    \"\"\"\n",
    "    주어진 문장에서 단어 벡터의 평균을 구하는 함수(임베딩벡터의 평균)\n",
    "    \"\"\"\n",
    "    # 속도를 위해 0으로 채운 배열로 초기화 한다.\n",
    "    featureVec = np.zeros((num_features,),dtype=\"float32\")\n",
    "\n",
    "    nwords = 0.\n",
    "    # Index2word는 모델의 사전에 있는 단어명을 담은 리스트이다.\n",
    "    # 속도를 위해 set 형태로 초기화 한다.\n",
    "    index2word_set = set(model.wv.index2word)\n",
    "    # 루프를 돌며 모델 사전에 포함이 되는 단어라면 피처에 추가한다.\n",
    "    for word in words:\n",
    "        if word in index2word_set:\n",
    "            nwords = nwords + 1.\n",
    "            featureVec = np.add(featureVec,model[word])\n",
    "    # 결과를 단어수로 나누어 평균을 구한다.\n",
    "    featureVec = np.divide(featureVec,nwords)\n",
    "    return featureVec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getAvgFeatureVecs(reviews, model, num_features):\n",
    "    # 리뷰 단어 목록의 각각에 대한 평균 feature 벡터를 계산하고 \n",
    "    # 2D numpy 배열을 반환한다.\n",
    "    \n",
    "    # 카운터를 초기화 한다.\n",
    "    counter = 0.\n",
    "    # 속도를 위해 2D 넘파이 배열을 미리 할당한다.\n",
    "    reviewFeatureVecs = np.zeros(\n",
    "        (len(reviews),num_features),dtype=\"float32\")\n",
    "    \n",
    "    for review in reviews:\n",
    "       # 매 1000개 리뷰마다 상태를 출력\n",
    "       if counter%1000. == 0.:\n",
    "           print(\"Review %d of %d\" % (counter, len(reviews)))\n",
    "       # 평균 피처 벡터를 만들기 위해 위에서 정의한 함수를 호출한다.\n",
    "    # 해당 row의 review의 토큰들의 임베딩벡터숫자를 평균낸다.(즉, review별로 임베딩벡터의 평균을 내는 것.)\n",
    "       reviewFeatureVecs[int(counter)] = makeFeatureVec(review, model, \\\n",
    "           num_features)\n",
    "       # 카운터를 증가시킨다.\n",
    "       counter = counter + 1.\n",
    "    return reviewFeatureVecs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 멀티스레드로 4개의 워커를 사용해 처리한다.\n",
    "def getCleanReviews(reviews):\n",
    "    clean_reviews = []\n",
    "    clean_reviews = KaggleWord2VecUtility.apply_by_multiprocessing(\\\n",
    "        reviews[\"Phrase\"], KaggleWord2VecUtility.review_to_wordlist,\\\n",
    "        workers=4)\n",
    "    return clean_reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Review 0 of 156060\n",
      "Review 1000 of 156060\n",
      "Review 2000 of 156060\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:16: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n",
      "  app.launch_new_instance()\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:18: RuntimeWarning: invalid value encountered in true_divide\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Review 3000 of 156060\n",
      "Review 4000 of 156060\n",
      "Review 5000 of 156060\n",
      "Review 6000 of 156060\n",
      "Review 7000 of 156060\n",
      "Review 8000 of 156060\n",
      "Review 9000 of 156060\n",
      "Review 10000 of 156060\n",
      "Review 11000 of 156060\n",
      "Review 12000 of 156060\n",
      "Review 13000 of 156060\n",
      "Review 14000 of 156060\n",
      "Review 15000 of 156060\n",
      "Review 16000 of 156060\n",
      "Review 17000 of 156060\n",
      "Review 18000 of 156060\n",
      "Review 19000 of 156060\n",
      "Review 20000 of 156060\n",
      "Review 21000 of 156060\n",
      "Review 22000 of 156060\n",
      "Review 23000 of 156060\n",
      "Review 24000 of 156060\n",
      "Review 25000 of 156060\n",
      "Review 26000 of 156060\n",
      "Review 27000 of 156060\n",
      "Review 28000 of 156060\n",
      "Review 29000 of 156060\n",
      "Review 30000 of 156060\n",
      "Review 31000 of 156060\n",
      "Review 32000 of 156060\n",
      "Review 33000 of 156060\n",
      "Review 34000 of 156060\n",
      "Review 35000 of 156060\n",
      "Review 36000 of 156060\n",
      "Review 37000 of 156060\n",
      "Review 38000 of 156060\n",
      "Review 39000 of 156060\n",
      "Review 40000 of 156060\n",
      "Review 41000 of 156060\n",
      "Review 42000 of 156060\n",
      "Review 43000 of 156060\n",
      "Review 44000 of 156060\n",
      "Review 45000 of 156060\n",
      "Review 46000 of 156060\n",
      "Review 47000 of 156060\n",
      "Review 48000 of 156060\n",
      "Review 49000 of 156060\n",
      "Review 50000 of 156060\n",
      "Review 51000 of 156060\n",
      "Review 52000 of 156060\n",
      "Review 53000 of 156060\n",
      "Review 54000 of 156060\n",
      "Review 55000 of 156060\n",
      "Review 56000 of 156060\n",
      "Review 57000 of 156060\n",
      "Review 58000 of 156060\n",
      "Review 59000 of 156060\n",
      "Review 60000 of 156060\n",
      "Review 61000 of 156060\n",
      "Review 62000 of 156060\n",
      "Review 63000 of 156060\n",
      "Review 64000 of 156060\n",
      "Review 65000 of 156060\n",
      "Review 66000 of 156060\n",
      "Review 67000 of 156060\n",
      "Review 68000 of 156060\n",
      "Review 69000 of 156060\n",
      "Review 70000 of 156060\n",
      "Review 71000 of 156060\n",
      "Review 72000 of 156060\n",
      "Review 73000 of 156060\n",
      "Review 74000 of 156060\n",
      "Review 75000 of 156060\n",
      "Review 76000 of 156060\n",
      "Review 77000 of 156060\n",
      "Review 78000 of 156060\n",
      "Review 79000 of 156060\n",
      "Review 80000 of 156060\n",
      "Review 81000 of 156060\n",
      "Review 82000 of 156060\n",
      "Review 83000 of 156060\n",
      "Review 84000 of 156060\n",
      "Review 85000 of 156060\n",
      "Review 86000 of 156060\n",
      "Review 87000 of 156060\n",
      "Review 88000 of 156060\n",
      "Review 89000 of 156060\n",
      "Review 90000 of 156060\n",
      "Review 91000 of 156060\n",
      "Review 92000 of 156060\n",
      "Review 93000 of 156060\n",
      "Review 94000 of 156060\n",
      "Review 95000 of 156060\n",
      "Review 96000 of 156060\n",
      "Review 97000 of 156060\n",
      "Review 98000 of 156060\n",
      "Review 99000 of 156060\n",
      "Review 100000 of 156060\n",
      "Review 101000 of 156060\n",
      "Review 102000 of 156060\n",
      "Review 103000 of 156060\n",
      "Review 104000 of 156060\n",
      "Review 105000 of 156060\n",
      "Review 106000 of 156060\n",
      "Review 107000 of 156060\n",
      "Review 108000 of 156060\n",
      "Review 109000 of 156060\n",
      "Review 110000 of 156060\n",
      "Review 111000 of 156060\n",
      "Review 112000 of 156060\n",
      "Review 113000 of 156060\n",
      "Review 114000 of 156060\n",
      "Review 115000 of 156060\n",
      "Review 116000 of 156060\n",
      "Review 117000 of 156060\n",
      "Review 118000 of 156060\n",
      "Review 119000 of 156060\n",
      "Review 120000 of 156060\n",
      "Review 121000 of 156060\n",
      "Review 122000 of 156060\n",
      "Review 123000 of 156060\n",
      "Review 124000 of 156060\n",
      "Review 125000 of 156060\n",
      "Review 126000 of 156060\n",
      "Review 127000 of 156060\n",
      "Review 128000 of 156060\n",
      "Review 129000 of 156060\n",
      "Review 130000 of 156060\n",
      "Review 131000 of 156060\n",
      "Review 132000 of 156060\n",
      "Review 133000 of 156060\n",
      "Review 134000 of 156060\n",
      "Review 135000 of 156060\n",
      "Review 136000 of 156060\n",
      "Review 137000 of 156060\n",
      "Review 138000 of 156060\n",
      "Review 139000 of 156060\n",
      "Review 140000 of 156060\n",
      "Review 141000 of 156060\n",
      "Review 142000 of 156060\n",
      "Review 143000 of 156060\n",
      "Review 144000 of 156060\n",
      "Review 145000 of 156060\n",
      "Review 146000 of 156060\n",
      "Review 147000 of 156060\n",
      "Review 148000 of 156060\n",
      "Review 149000 of 156060\n",
      "Review 150000 of 156060\n",
      "Review 151000 of 156060\n",
      "Review 152000 of 156060\n",
      "Review 153000 of 156060\n",
      "Review 154000 of 156060\n",
      "Review 155000 of 156060\n",
      "Review 156000 of 156060\n"
     ]
    }
   ],
   "source": [
    "trainDataVecstrainDat  = getAvgFeatureVecs(\\\n",
    "    getCleanReviews(train), model, num_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Review 0 of 66292\n",
      "Review 1000 of 66292\n",
      "Review 2000 of 66292\n",
      "Review 3000 of 66292\n",
      "Review 4000 of 66292\n",
      "Review 5000 of 66292\n",
      "Review 6000 of 66292\n",
      "Review 7000 of 66292\n",
      "Review 8000 of 66292\n",
      "Review 9000 of 66292\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:16: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n",
      "  app.launch_new_instance()\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:18: RuntimeWarning: invalid value encountered in true_divide\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Review 10000 of 66292\n",
      "Review 11000 of 66292\n",
      "Review 12000 of 66292\n",
      "Review 13000 of 66292\n",
      "Review 14000 of 66292\n",
      "Review 15000 of 66292\n",
      "Review 16000 of 66292\n",
      "Review 17000 of 66292\n",
      "Review 18000 of 66292\n",
      "Review 19000 of 66292\n",
      "Review 20000 of 66292\n",
      "Review 21000 of 66292\n",
      "Review 22000 of 66292\n",
      "Review 23000 of 66292\n",
      "Review 24000 of 66292\n",
      "Review 25000 of 66292\n",
      "Review 26000 of 66292\n",
      "Review 27000 of 66292\n",
      "Review 28000 of 66292\n",
      "Review 29000 of 66292\n",
      "Review 30000 of 66292\n",
      "Review 31000 of 66292\n",
      "Review 32000 of 66292\n",
      "Review 33000 of 66292\n",
      "Review 34000 of 66292\n",
      "Review 35000 of 66292\n",
      "Review 36000 of 66292\n",
      "Review 37000 of 66292\n",
      "Review 38000 of 66292\n",
      "Review 39000 of 66292\n",
      "Review 40000 of 66292\n",
      "Review 41000 of 66292\n",
      "Review 42000 of 66292\n",
      "Review 43000 of 66292\n",
      "Review 44000 of 66292\n",
      "Review 45000 of 66292\n",
      "Review 46000 of 66292\n",
      "Review 47000 of 66292\n",
      "Review 48000 of 66292\n",
      "Review 49000 of 66292\n",
      "Review 50000 of 66292\n",
      "Review 51000 of 66292\n",
      "Review 52000 of 66292\n",
      "Review 53000 of 66292\n",
      "Review 54000 of 66292\n",
      "Review 55000 of 66292\n",
      "Review 56000 of 66292\n",
      "Review 57000 of 66292\n",
      "Review 58000 of 66292\n",
      "Review 59000 of 66292\n",
      "Review 60000 of 66292\n",
      "Review 61000 of 66292\n",
      "Review 62000 of 66292\n",
      "Review 63000 of 66292\n",
      "Review 64000 of 66292\n",
      "Review 65000 of 66292\n",
      "Review 66000 of 66292\n"
     ]
    }
   ],
   "source": [
    "testDataVecs = getAvgFeatureVecs(\\\n",
    "        getCleanReviews(test), model, num_features )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Input contains NaN, infinity or a value too large for dtype('float32').",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-167-659ab0a3f57d>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mforest\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mRandomForestClassifier\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn_estimators\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m100\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m2018\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrainDataVecstrainDat\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Sentiment'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m    245\u001b[0m         \"\"\"\n\u001b[0;32m    246\u001b[0m         \u001b[1;31m# Validate or convert input data\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 247\u001b[1;33m         \u001b[0mX\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maccept_sparse\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"csc\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mDTYPE\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    248\u001b[0m         \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maccept_sparse\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'csc'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mensure_2d\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    249\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0msample_weight\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[1;34m(array, accept_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, warn_on_dtype, estimator)\u001b[0m\n\u001b[0;32m    451\u001b[0m                              % (array.ndim, estimator_name))\n\u001b[0;32m    452\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mforce_all_finite\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 453\u001b[1;33m             \u001b[0m_assert_all_finite\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    454\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    455\u001b[0m     \u001b[0mshape_repr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_shape_repr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36m_assert_all_finite\u001b[1;34m(X)\u001b[0m\n\u001b[0;32m     42\u001b[0m             and not np.isfinite(X).all()):\n\u001b[0;32m     43\u001b[0m         raise ValueError(\"Input contains NaN, infinity\"\n\u001b[1;32m---> 44\u001b[1;33m                          \" or a value too large for %r.\" % X.dtype)\n\u001b[0m\u001b[0;32m     45\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     46\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Input contains NaN, infinity or a value too large for dtype('float32')."
     ]
    }
   ],
   "source": [
    "forest = RandomForestClassifier(n_estimators=100, random_state=2018).fit(trainDataVecstrainDat, train['Sentiment'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['the',\n",
       " 'a',\n",
       " 'of',\n",
       " 'and',\n",
       " 'to',\n",
       " 'it',\n",
       " 's',\n",
       " 'in',\n",
       " 'is',\n",
       " 'that',\n",
       " 'as',\n",
       " 'film',\n",
       " 'with',\n",
       " 'movi',\n",
       " 'for',\n",
       " 'an',\n",
       " 'be',\n",
       " 'this',\n",
       " 'but',\n",
       " 'on',\n",
       " 'you',\n",
       " 't',\n",
       " 'n',\n",
       " 'by',\n",
       " 'one',\n",
       " 'more',\n",
       " 'his',\n",
       " 'about',\n",
       " 'not',\n",
       " 'like',\n",
       " 'at',\n",
       " 'or',\n",
       " 'than',\n",
       " 'from',\n",
       " 'all',\n",
       " 'have',\n",
       " 'are',\n",
       " 'has',\n",
       " 'make',\n",
       " 'charact',\n",
       " 'so',\n",
       " 'stori',\n",
       " 'out',\n",
       " 'time',\n",
       " 'up',\n",
       " 'rrb',\n",
       " 'most',\n",
       " 'who',\n",
       " 'good',\n",
       " 'too',\n",
       " 'into',\n",
       " 'lrb',\n",
       " 'work',\n",
       " 'comedi',\n",
       " 'if',\n",
       " 'what',\n",
       " 'their',\n",
       " 'no',\n",
       " 'much',\n",
       " 'i',\n",
       " 'can',\n",
       " 'your',\n",
       " 'way',\n",
       " 'just',\n",
       " 'life',\n",
       " 'some',\n",
       " 'even',\n",
       " 'feel',\n",
       " 'perform',\n",
       " 'doe',\n",
       " 'will',\n",
       " 'love',\n",
       " 'well',\n",
       " 'look',\n",
       " 'littl',\n",
       " 'funni',\n",
       " 'do',\n",
       " 'veri',\n",
       " 'director',\n",
       " 'been',\n",
       " 'ani',\n",
       " 'bad',\n",
       " 'get',\n",
       " 'onli',\n",
       " 'come',\n",
       " 'which',\n",
       " 'year',\n",
       " 'he',\n",
       " 'other',\n",
       " 'new',\n",
       " 'there',\n",
       " 'see',\n",
       " 'enough',\n",
       " 'her',\n",
       " 'was',\n",
       " 'own',\n",
       " 'action',\n",
       " 'us',\n",
       " 'they',\n",
       " 'watch',\n",
       " 'thing',\n",
       " 'made',\n",
       " 'old',\n",
       " 'audienc',\n",
       " 'entertain',\n",
       " 'take',\n",
       " 'end',\n",
       " 'plot',\n",
       " 'two',\n",
       " 'someth',\n",
       " 'interest',\n",
       " 'minut',\n",
       " 'act',\n",
       " 'would',\n",
       " 'go',\n",
       " 'emot',\n",
       " 'best',\n",
       " 'through',\n",
       " 'never',\n",
       " 'we',\n",
       " 'seem',\n",
       " 'mani',\n",
       " 'over',\n",
       " 'peopl',\n",
       " 'off',\n",
       " 'when',\n",
       " 'world',\n",
       " 'human',\n",
       " 'drama',\n",
       " 'self',\n",
       " 'them',\n",
       " 'how',\n",
       " 'live',\n",
       " 'first',\n",
       " 'give',\n",
       " 'may',\n",
       " 'could',\n",
       " 'long',\n",
       " 'humor',\n",
       " 'screen',\n",
       " 'better',\n",
       " 'direct',\n",
       " 'sens',\n",
       " 'heart',\n",
       " 'cast',\n",
       " 'great',\n",
       " 'play',\n",
       " 'big',\n",
       " 're',\n",
       " 'realli',\n",
       " 'those',\n",
       " 'actor',\n",
       " 'man',\n",
       " 'filmmak',\n",
       " 'moment',\n",
       " 'without',\n",
       " 'real',\n",
       " 'famili',\n",
       " 'everi',\n",
       " 'ever',\n",
       " 'hard',\n",
       " 'few',\n",
       " 'american',\n",
       " 'scene',\n",
       " 'anoth',\n",
       " 'should',\n",
       " 'power',\n",
       " 'tri',\n",
       " 'pictur',\n",
       " 'such',\n",
       " 'hollywood',\n",
       " 'surpris',\n",
       " 'still',\n",
       " 'find',\n",
       " 'laugh',\n",
       " 'both',\n",
       " 'star',\n",
       " 'hour',\n",
       " 'want',\n",
       " 'visual',\n",
       " 'enjoy',\n",
       " 'down',\n",
       " 'origin',\n",
       " 'fun',\n",
       " 'beauti',\n",
       " 'turn',\n",
       " 'show',\n",
       " 'script',\n",
       " 'noth',\n",
       " 'while',\n",
       " 'between',\n",
       " 'kind',\n",
       " 'less',\n",
       " 'kid',\n",
       " 'often',\n",
       " 'think',\n",
       " 'might',\n",
       " 'point',\n",
       " 'were',\n",
       " 'high',\n",
       " 'far',\n",
       " 'lot',\n",
       " 'our',\n",
       " 'music',\n",
       " 'need',\n",
       " 'had',\n",
       " 'war',\n",
       " 'keep',\n",
       " 'back',\n",
       " 'these',\n",
       " 'also',\n",
       " 'after',\n",
       " 'seen',\n",
       " 'thriller',\n",
       " 'know',\n",
       " 'befor',\n",
       " 'day',\n",
       " 'rather',\n",
       " 'right',\n",
       " 'idea',\n",
       " 'set',\n",
       " 'becaus',\n",
       " 'effect',\n",
       " 'young',\n",
       " 'cultur',\n",
       " 'run',\n",
       " 'full',\n",
       " 'charm',\n",
       " 'subject',\n",
       " 'almost',\n",
       " 'becom',\n",
       " 'tale',\n",
       " 'materi',\n",
       " 'style',\n",
       " 'place',\n",
       " 'intellig',\n",
       " 'age',\n",
       " 'care',\n",
       " 'my',\n",
       " 'move',\n",
       " 'art',\n",
       " 'cinema',\n",
       " 'lack',\n",
       " 'ultim',\n",
       " 'here',\n",
       " 'anim',\n",
       " 'quit',\n",
       " 'documentari',\n",
       " 'dialogu',\n",
       " 'flick',\n",
       " 'dark',\n",
       " 've',\n",
       " 'piec',\n",
       " 'face',\n",
       " 'romant',\n",
       " 'half',\n",
       " 'me',\n",
       " 'yet',\n",
       " 'same',\n",
       " 'eye',\n",
       " 'imagin',\n",
       " 'itself',\n",
       " 'comic',\n",
       " 'bit',\n",
       " 'say',\n",
       " 'featur',\n",
       " 'him',\n",
       " 'person',\n",
       " 'fan',\n",
       " 'sweet',\n",
       " 'use',\n",
       " 'thought',\n",
       " 'part',\n",
       " 'video',\n",
       " 'special',\n",
       " 'perfect',\n",
       " 'mind',\n",
       " 'offer',\n",
       " 'experi',\n",
       " 'compel',\n",
       " 'last',\n",
       " 'worth',\n",
       " 'wonder',\n",
       " 'believ',\n",
       " 'near',\n",
       " 'girl',\n",
       " 'll',\n",
       " 'clever',\n",
       " 'leav',\n",
       " 'talent',\n",
       " 'mean',\n",
       " 'ca',\n",
       " 'polit',\n",
       " 'women',\n",
       " 'though',\n",
       " 'inspir',\n",
       " 'histori',\n",
       " 'narrat',\n",
       " 'writer',\n",
       " 'where',\n",
       " 'light',\n",
       " 'actual',\n",
       " 'natur',\n",
       " 'spirit',\n",
       " 'three',\n",
       " 'anyth',\n",
       " 'did',\n",
       " 'familiar',\n",
       " 'hand',\n",
       " 'touch',\n",
       " 'least',\n",
       " 'amus',\n",
       " 'final',\n",
       " 'dramat',\n",
       " 'theater',\n",
       " 'engag',\n",
       " 'viewer',\n",
       " 'under',\n",
       " 'togeth',\n",
       " 'fascin',\n",
       " 'around',\n",
       " 'pace',\n",
       " 'genr',\n",
       " 'matter',\n",
       " 'wit',\n",
       " 'tell',\n",
       " 'sometim',\n",
       " 'serious',\n",
       " 'predict',\n",
       " 'true',\n",
       " 'book',\n",
       " 'low',\n",
       " 'dull',\n",
       " 'creat',\n",
       " 'side',\n",
       " 'silli',\n",
       " 'put',\n",
       " 'expect',\n",
       " 'away',\n",
       " 'titl',\n",
       " 'pretti',\n",
       " 'level',\n",
       " 'again',\n",
       " 'call',\n",
       " 'reason',\n",
       " 'line',\n",
       " 'she',\n",
       " 'artist',\n",
       " 'start',\n",
       " 'short',\n",
       " 'boy',\n",
       " 'classic',\n",
       " 'modern',\n",
       " 'sentiment',\n",
       " 'effort',\n",
       " 'whi',\n",
       " 'head',\n",
       " 'cinemat',\n",
       " 'certain',\n",
       " 'smart',\n",
       " 'view',\n",
       " 'guy',\n",
       " 'bore',\n",
       " 'manag',\n",
       " 'onc',\n",
       " 'forc',\n",
       " 'obvious',\n",
       " 'd',\n",
       " 'then',\n",
       " 'shot',\n",
       " 'joke',\n",
       " 'twist',\n",
       " 'horror',\n",
       " 'tv',\n",
       " 'anyon',\n",
       " 'delight',\n",
       " 'product',\n",
       " 'satisfi',\n",
       " 'children',\n",
       " 'clich',\n",
       " 'pain',\n",
       " 'screenplay',\n",
       " 'sad',\n",
       " 'done',\n",
       " 'wild',\n",
       " 'possibl',\n",
       " 'intrigu',\n",
       " 'black',\n",
       " 'appeal',\n",
       " 'strong',\n",
       " 'moral',\n",
       " 'seri',\n",
       " 'summer',\n",
       " 'rare',\n",
       " 'romanc',\n",
       " 'studi',\n",
       " 'whose',\n",
       " 'suspens',\n",
       " 'success',\n",
       " 'happen',\n",
       " 'men',\n",
       " 'chang',\n",
       " 'fresh',\n",
       " 'odd',\n",
       " 'particular',\n",
       " 'relationship',\n",
       " 'entir',\n",
       " 'each',\n",
       " 'attempt',\n",
       " 'premis',\n",
       " 'complet',\n",
       " 'strang',\n",
       " 'sinc',\n",
       " 'flaw',\n",
       " 'pleasur',\n",
       " 'tone',\n",
       " 'energi',\n",
       " 'bring',\n",
       " 'deliv',\n",
       " 'middl',\n",
       " 'adventur',\n",
       " 'crime',\n",
       " 'game',\n",
       " 'insight',\n",
       " 'dead',\n",
       " 'formula',\n",
       " 'sequenc',\n",
       " 'messag',\n",
       " 'stand',\n",
       " 'differ',\n",
       " 'hope',\n",
       " 'cut',\n",
       " 'past',\n",
       " 'small',\n",
       " 'whole',\n",
       " 'easi',\n",
       " 'close',\n",
       " 'win',\n",
       " 'teen',\n",
       " 'mysteri',\n",
       " 'open',\n",
       " 'death',\n",
       " 'rich',\n",
       " 'usual',\n",
       " 'simpli',\n",
       " 'hit',\n",
       " 'woman',\n",
       " 'sequel',\n",
       " 'especi',\n",
       " 'camera',\n",
       " 'project',\n",
       " 'problem',\n",
       " 'social',\n",
       " 'alway',\n",
       " 'situat',\n",
       " 'generat',\n",
       " 'version',\n",
       " 'gag',\n",
       " 'impress',\n",
       " 'sit',\n",
       " 'complex',\n",
       " 'everyth',\n",
       " 'solid',\n",
       " 'word',\n",
       " 'school',\n",
       " 'help',\n",
       " 'promis',\n",
       " 'himself',\n",
       " 'role',\n",
       " 'portrait',\n",
       " 'imag',\n",
       " 'tragedi',\n",
       " 'lead',\n",
       " 'next',\n",
       " 'french',\n",
       " 'import',\n",
       " 'm',\n",
       " 'worst',\n",
       " 'contriv',\n",
       " 'goe',\n",
       " 'john',\n",
       " 'theme',\n",
       " 'prove',\n",
       " 'fail',\n",
       " 'recent',\n",
       " 'mr',\n",
       " 'opera',\n",
       " 'dream',\n",
       " 'psycholog',\n",
       " 'passion',\n",
       " 'exercis',\n",
       " 'home',\n",
       " 'quirki',\n",
       " 'fine',\n",
       " 'sure',\n",
       " 'melodrama',\n",
       " 'instead',\n",
       " 'convinc',\n",
       " 'fashion',\n",
       " 'probabl',\n",
       " 'adult',\n",
       " 'miss',\n",
       " 'remark',\n",
       " 'fill',\n",
       " 'fair',\n",
       " 'either',\n",
       " 'remain',\n",
       " 'debut',\n",
       " 'clear',\n",
       " 'let',\n",
       " 'fall',\n",
       " 'everyon',\n",
       " 'event',\n",
       " 'color',\n",
       " 'element',\n",
       " 'stuff',\n",
       " 'thin',\n",
       " 'realiti',\n",
       " 'honest',\n",
       " 'detail',\n",
       " 'shock',\n",
       " 'second',\n",
       " 'reveal',\n",
       " 'question',\n",
       " 'hous',\n",
       " 'written',\n",
       " 'dumb',\n",
       " 'now',\n",
       " 'understand',\n",
       " 'produc',\n",
       " 'extrem',\n",
       " 'sort',\n",
       " 'hold',\n",
       " 'grow',\n",
       " 'truli',\n",
       " 'slight',\n",
       " 'present',\n",
       " 'despit',\n",
       " 'satir',\n",
       " 'concept',\n",
       " 'edit',\n",
       " 'fantasi',\n",
       " 'develop',\n",
       " 'sex',\n",
       " 'fire',\n",
       " 'soul',\n",
       " 'histor',\n",
       " 'insid',\n",
       " 'flat',\n",
       " 'cold',\n",
       " 'storytel',\n",
       " 'pop',\n",
       " 'larg',\n",
       " 'imposs',\n",
       " 'els',\n",
       " 'shoot',\n",
       " 'dog',\n",
       " 'beyond',\n",
       " 'involv',\n",
       " 'top',\n",
       " 'nice',\n",
       " 'poor',\n",
       " 'excit',\n",
       " 'slow',\n",
       " 'quiet',\n",
       " 'creativ',\n",
       " 'serv',\n",
       " 'sever',\n",
       " 'class',\n",
       " 'hilari',\n",
       " 'parent',\n",
       " 'break',\n",
       " 'suffer',\n",
       " 'number',\n",
       " 'explor',\n",
       " 'manner',\n",
       " 'wo',\n",
       " 'de',\n",
       " 'alreadi',\n",
       " 'sound',\n",
       " 'hero',\n",
       " 'invent',\n",
       " 'left',\n",
       " 'pull',\n",
       " 'potenti',\n",
       " 'deepli',\n",
       " 'monster',\n",
       " 'issu',\n",
       " 'master',\n",
       " 'deserv',\n",
       " 'earnest',\n",
       " 'genuin',\n",
       " 'except',\n",
       " 'attract',\n",
       " 'releas',\n",
       " 'mark',\n",
       " 'bland',\n",
       " 'name',\n",
       " 'themselv',\n",
       " 'mix',\n",
       " 'execut',\n",
       " 'follow',\n",
       " 'michael',\n",
       " 'abov',\n",
       " 'citi',\n",
       " 'begin',\n",
       " 'ride',\n",
       " 'deep',\n",
       " 'otherwis',\n",
       " 'allow',\n",
       " 'intens',\n",
       " 'seat',\n",
       " 'wast',\n",
       " 'affect',\n",
       " 'rock',\n",
       " 'captur',\n",
       " 'against',\n",
       " 'singl',\n",
       " 'mood',\n",
       " 'write',\n",
       " 'wait',\n",
       " 'credit',\n",
       " 'screenwrit',\n",
       " 'provid',\n",
       " 'gentl',\n",
       " 'wrong',\n",
       " 'deal',\n",
       " 'figur',\n",
       " 'exploit',\n",
       " 'tradit',\n",
       " 'attent',\n",
       " 'approach',\n",
       " 'actress',\n",
       " 'b',\n",
       " 'creepi',\n",
       " 'mere',\n",
       " 'occasion',\n",
       " 'read',\n",
       " 'fear',\n",
       " 'must',\n",
       " 'dure',\n",
       " 'bare',\n",
       " 'mild',\n",
       " 'violenc',\n",
       " 'novel',\n",
       " 'suppos',\n",
       " 'along',\n",
       " 'cool',\n",
       " 'water',\n",
       " 'general',\n",
       " 'period',\n",
       " 'memori',\n",
       " 'weird',\n",
       " 'tear',\n",
       " 'simpl',\n",
       " 'soap',\n",
       " 'gorgeous',\n",
       " 'budget',\n",
       " 'truth',\n",
       " 'intent',\n",
       " 'appear',\n",
       " 'four',\n",
       " 'date',\n",
       " 'career',\n",
       " 'easili',\n",
       " 'achiev',\n",
       " 'night',\n",
       " 'frustrat',\n",
       " 'brilliant',\n",
       " 'episod',\n",
       " 'qualiti',\n",
       " 'white',\n",
       " 'brother',\n",
       " 'warm',\n",
       " 'memor',\n",
       " 'examin',\n",
       " 'carri',\n",
       " 'difficult',\n",
       " 'road',\n",
       " 'rememb',\n",
       " 'vision',\n",
       " 'damn',\n",
       " 'grace',\n",
       " 'strike',\n",
       " 'fight',\n",
       " 'found',\n",
       " 'fact',\n",
       " 'admir',\n",
       " 'edg',\n",
       " 'standard',\n",
       " 'straight',\n",
       " 'heavi',\n",
       " 'tast',\n",
       " 'whether',\n",
       " 'equal',\n",
       " 'thrill',\n",
       " 'room',\n",
       " 'conscious',\n",
       " 'portray',\n",
       " 'none',\n",
       " 'oscar',\n",
       " 'sustain',\n",
       " 'process',\n",
       " 'york',\n",
       " 'connect',\n",
       " 'robert',\n",
       " 'pay',\n",
       " 'adapt',\n",
       " 'happi',\n",
       " 'spi',\n",
       " 'mess',\n",
       " 'save',\n",
       " 'friend',\n",
       " 'case',\n",
       " 'definit',\n",
       " 'disappoint',\n",
       " 'busi',\n",
       " 'cute',\n",
       " 'valu',\n",
       " 'given',\n",
       " 'respect',\n",
       " 'rate',\n",
       " 'fit',\n",
       " 'terrif',\n",
       " 'chill',\n",
       " 'stupid',\n",
       " 'construct',\n",
       " 'major',\n",
       " 'got',\n",
       " 'target',\n",
       " 'express',\n",
       " 'recommend',\n",
       " 'exist',\n",
       " 'quick',\n",
       " 'cheap',\n",
       " 'america',\n",
       " 'base',\n",
       " 'dri',\n",
       " 'mother',\n",
       " 'talk',\n",
       " 'realiz',\n",
       " 'refresh',\n",
       " 'sexual',\n",
       " 'car',\n",
       " 'struggl',\n",
       " 'tire',\n",
       " 'ii',\n",
       " 'coupl',\n",
       " 'nor',\n",
       " 'th',\n",
       " 'huge',\n",
       " 'nation',\n",
       " 'previous',\n",
       " 'lost',\n",
       " 'die',\n",
       " 'utter',\n",
       " 'scari',\n",
       " 'unexpect',\n",
       " 'told',\n",
       " 'ambiti',\n",
       " 'escap',\n",
       " 'magic',\n",
       " 'gone',\n",
       " 'pleas',\n",
       " 'skill',\n",
       " 'purpos',\n",
       " 'score',\n",
       " 'disney',\n",
       " 'plenti',\n",
       " 'air',\n",
       " 'loud',\n",
       " 'neither',\n",
       " 'sensit',\n",
       " 'aw',\n",
       " 'frame',\n",
       " 'drag',\n",
       " 'depress',\n",
       " 'teenag',\n",
       " 'hip',\n",
       " 'crowd',\n",
       " 'faith',\n",
       " 'welcom',\n",
       " 'tragic',\n",
       " 'term',\n",
       " 'cartoon',\n",
       " 'unsettl',\n",
       " 'exact',\n",
       " 'ugli',\n",
       " 'convent',\n",
       " 'excel',\n",
       " 'balanc',\n",
       " 'urban',\n",
       " 'share',\n",
       " 'amount',\n",
       " 'skin',\n",
       " 'observ',\n",
       " 'desper',\n",
       " 'free',\n",
       " 'tension',\n",
       " 'form',\n",
       " 'decad',\n",
       " 'futur',\n",
       " 'craft',\n",
       " 'speak',\n",
       " 'mediocr',\n",
       " 'contemporari',\n",
       " 'alien',\n",
       " 'conflict',\n",
       " 'smile',\n",
       " 'unlik',\n",
       " 'blood',\n",
       " 'complic',\n",
       " 'week',\n",
       " 'murder',\n",
       " 'sincer',\n",
       " 'stage',\n",
       " 'sport',\n",
       " 'fi',\n",
       " 'bodi',\n",
       " 'pretenti',\n",
       " 'depth',\n",
       " 'abl',\n",
       " 'centuri',\n",
       " 'manipul',\n",
       " 'root',\n",
       " 'sci',\n",
       " 'reson',\n",
       " 'dare',\n",
       " 'relat',\n",
       " 'job',\n",
       " 'gay',\n",
       " 'gross',\n",
       " 'challeng',\n",
       " 'combin',\n",
       " 'latest',\n",
       " 'battl',\n",
       " 'decent',\n",
       " 'fiction',\n",
       " 'colleg',\n",
       " 'sign',\n",
       " 'epic',\n",
       " 'song',\n",
       " 'plain',\n",
       " 'atmospher',\n",
       " 'pass',\n",
       " 'main',\n",
       " 'pure',\n",
       " 'voic',\n",
       " 'danc',\n",
       " 'thorough',\n",
       " 'crazi',\n",
       " 'consid',\n",
       " 'ask',\n",
       " 'conclus',\n",
       " 'uniqu',\n",
       " 'trip',\n",
       " 'remind',\n",
       " 'cross',\n",
       " 'somewhat',\n",
       " 'brain',\n",
       " 'femal',\n",
       " 'kill',\n",
       " 'remak',\n",
       " 'consider',\n",
       " 'chase',\n",
       " 'worthi',\n",
       " 'countri',\n",
       " 'stay',\n",
       " 'pack',\n",
       " 'indulg',\n",
       " 'spiritu',\n",
       " 'lose',\n",
       " 'fast',\n",
       " 'obsess',\n",
       " 'reach',\n",
       " 'ill',\n",
       " 'queen',\n",
       " 'determin',\n",
       " 'deriv',\n",
       " 'troubl',\n",
       " 'univers',\n",
       " 'rise',\n",
       " 'altern',\n",
       " 'emerg',\n",
       " 'impact',\n",
       " 'wish',\n",
       " 'hate',\n",
       " 'comfort',\n",
       " 'david',\n",
       " 'fulli',\n",
       " 'bite',\n",
       " 'behind',\n",
       " 'green',\n",
       " 'favor',\n",
       " 'televis',\n",
       " 'felt',\n",
       " 'seek',\n",
       " 'length',\n",
       " 'journey',\n",
       " 'critic',\n",
       " 'burn',\n",
       " 'suggest',\n",
       " 'co',\n",
       " 'goofi',\n",
       " 'terribl',\n",
       " 'step',\n",
       " 'answer',\n",
       " 'british',\n",
       " 'concern',\n",
       " 'saw',\n",
       " 'confus',\n",
       " 'walk',\n",
       " 'celebr',\n",
       " 'compani',\n",
       " 'money',\n",
       " 'core',\n",
       " 'beat',\n",
       " 'protagonist',\n",
       " 'tedious',\n",
       " 'gun',\n",
       " 'structur',\n",
       " 'rest',\n",
       " 'draw',\n",
       " 'paint',\n",
       " 'total',\n",
       " 'condit',\n",
       " 'stylish',\n",
       " 'across',\n",
       " 'empti',\n",
       " 'record',\n",
       " 'drug',\n",
       " 'today',\n",
       " 'engross',\n",
       " 'limit',\n",
       " 'add',\n",
       " 'bear',\n",
       " 'servic',\n",
       " 'averag',\n",
       " 'chanc',\n",
       " 'routin',\n",
       " 'gift',\n",
       " 'throughout',\n",
       " 'includ',\n",
       " 'parti',\n",
       " 'medit',\n",
       " 'motion',\n",
       " 'absurd',\n",
       " 'era',\n",
       " 'result',\n",
       " 'rhythm',\n",
       " 'killer',\n",
       " 'overal',\n",
       " 'treat',\n",
       " 'evil',\n",
       " 'spielberg',\n",
       " 'secret',\n",
       " 'substanc',\n",
       " 'member',\n",
       " 'list',\n",
       " 'victim',\n",
       " 'sophist',\n",
       " 'bond',\n",
       " 'ago',\n",
       " 'wors',\n",
       " 'accept',\n",
       " 'friendship',\n",
       " 'opportun',\n",
       " 'storylin',\n",
       " 'forget',\n",
       " 'taken',\n",
       " 'throw',\n",
       " 'stop',\n",
       " 'wear',\n",
       " 'loss',\n",
       " 'shallow',\n",
       " 'space',\n",
       " 'guess',\n",
       " 'wind',\n",
       " 'doubt',\n",
       " 'studio',\n",
       " 'perspect',\n",
       " 'villain',\n",
       " 'roll',\n",
       " 'steven',\n",
       " 'notic',\n",
       " 'ya',\n",
       " 'hell',\n",
       " 'sea',\n",
       " 'damag',\n",
       " 'desir',\n",
       " 'vivid',\n",
       " 'warmth',\n",
       " 'adam',\n",
       " 'season',\n",
       " 'hole',\n",
       " 'outrag',\n",
       " 'late',\n",
       " 'hot',\n",
       " 'overcom',\n",
       " 'collect',\n",
       " ...]"
      ]
     },
     "execution_count": 169,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv.index2word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score = np.mean(cross_val_score(forest, trainDataVecstrainDat, train['Sentiment'], cv=5, scoring='roc_auc'))\n",
    "score"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
